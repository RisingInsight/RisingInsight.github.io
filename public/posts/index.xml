<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on RisingInsight&#39;s Blog</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on RisingInsight&#39;s Blog</description>
    <generator>Hugo -- 0.154.0</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 01 Jan 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>图片测试</title>
      <link>http://localhost:1313/posts/test-picture/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/test-picture/</guid>
      <description>&lt;p&gt;这是我的笔记正文。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;笔记截图&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/test-picture/2026-01-01-00-00-52.jpg&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>公式和代码测试</title>
      <link>http://localhost:1313/posts/test-math-code/</link>
      <pubDate>Wed, 01 Jan 2025 12:00:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/test-math-code/</guid>
      <description>&lt;h2 id=&#34;1-数学公式测试-mathjax&#34;&gt;1. 数学公式测试 (MathJax)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;行内公式：&lt;/strong&gt;
我们要计算 $E = mc^2$ 的能量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;块级公式：&lt;/strong&gt;
这是一个高斯积分：
&lt;/p&gt;
$$
\int_{-\infty}^{\infty} e^{-x^2} dx = \sqrt{\pi}
$$&lt;h2 id=&#34;2-代码块测试&#34;&gt;2. 代码块测试&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-3&#34;&gt;3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-4&#34;&gt;4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-5&#34;&gt;5&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-6&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-6&#34;&gt;6&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;fib&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fib&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fib&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fib&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/do/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/do/</guid>
      <description>&lt;p&gt;dx&lt;/p&gt;
&lt;p&gt;cxvxcvzx&lt;/p&gt;
&lt;p&gt;xczvxcz&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20260101181501930&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/do/index.assets/image-20260101181501930.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/posts/%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/</guid>
      <description>&lt;h1 id=&#34;图片&#34;&gt;图片&lt;/h1&gt;
&lt;p&gt;​	对于一张彩色图片而言，它有RGB三通道。&lt;strong&gt;R通道&lt;/strong&gt;：记录图像中每个像素的&lt;strong&gt;红色分量强度&lt;/strong&gt;（通常用0~255的数值表示，0表示无红色，255表示红色最亮）。&lt;strong&gt;G通道&lt;/strong&gt;：记录&lt;strong&gt;绿色分量强度&lt;/strong&gt;。&lt;strong&gt;B通道&lt;/strong&gt;：记录&lt;strong&gt;蓝色分量强度&lt;/strong&gt;。对于图片中的某一个像素而言，它有256x256x256种颜色，RGB三个通道组合而成。&lt;/p&gt;
&lt;h1 id=&#34;深度生成模型&#34;&gt;深度生成模型&lt;/h1&gt;
&lt;p&gt;​	文本生成，图片生成，视频生成。&lt;/p&gt;
&lt;p&gt;​	对于一个输入，可以有多种，甚至无穷种回答。输出可能比输入更加复杂且高纬&lt;/p&gt;
&lt;p&gt;​	一段文字转换为一个模型，模型需要进行大量的脑补。因为图片对应的文字有很多，一张图胜过千言万语。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20251222152235572&#34; loading=&#34;lazy&#34; src=&#34;./%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B.assets/image-20251222152235572.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	对于文字生成而言，主要采取逐个击破（Autoregressive，自回归），从输入文本计算出最可能的下一个字或者词（计算概率，选概率最大的），然后将其追加到输入文本的末尾，作为新的输入。然后重复，直到生成结束标记；图片生成的话，也可以采取这种方式进行。要画一只奔跑的狗，计算第一个像素最可能为什么颜色（概率最大），然后将第一个像素和文字作为新的输入，重复，知道生成结束标记。太浪费时间，==现在的图像生成不使用Autorgessvie自回归！！！==&lt;/p&gt;
&lt;p&gt;​	image-gpt：将2D图像转换为1D序列（得到256排的256个token），对于每一排的256个token，从输入token计算出最可能的下一个token，然后将其追加到输入token的末尾，作为新的输入。然后重复，直到生成结束标记。然后&lt;strong&gt;图片生成都是一排一排生成出来的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;、&lt;/p&gt;
&lt;p&gt;​	一步到位生成：直接预测256x256个每个像素点的颜色。得到的结果就是一个分布之内的，在这个分布之内的都是正确的输出。但是使用一步到位生成会导致每个像素点可能要画的图不一样（例如有的像素点是想画黑狗，有的想画白狗，有的向前跑，有的向后退，&amp;hellip;.）&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;​	为了解决这个问题，就需要使用Normal Distribution。通过Normal Distribution 得到可能的图片P(x|y)，然后文字就帮忙指导映射。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;variational-auto-encodervae&#34;&gt;Variational Auto-encoder(VAE)&lt;/h1&gt;
&lt;p&gt;​	把Normal Distribution采样得到的向量放进Decoder中&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20251222170720742&#34; loading=&#34;lazy&#34; src=&#34;./%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B.assets/image-20251222170720742.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;ae和vae结构&#34;&gt;AE和VAE结构&lt;/h2&gt;
&lt;p&gt;AE（自编码器）的核心是&lt;strong&gt;编码-解码-重建&lt;/strong&gt;，结构如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;输入&lt;/strong&gt;：原始图像 $X$（高维数据）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Encoder（编码器）&lt;/strong&gt;：将 $X$ 降维到低维隐空间（Latent Space），得到一个确定的隐向量 $z$（$z = \text{Encoder}(X)$）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decoder（解码器）&lt;/strong&gt;：将隐向量 $z$ 升维，还原回高维图像 $\hat{X}$（$\hat{X} = \text{Decoder}(z)$）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;训练目标&lt;/strong&gt;：最小化&lt;strong&gt;重建误差&lt;/strong&gt;（比如像素级MSE），即让 $\hat{X} \approx X$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​	AE能做好&lt;strong&gt;降维+重建&lt;/strong&gt;，但没法&lt;strong&gt;生成新数据&lt;/strong&gt;——因为训练后，每个 $X_i$ 和 $z_i$ 是&lt;strong&gt;一一对应&lt;/strong&gt;的（隐空间是&amp;quot;离散点&amp;quot;分布）。如果随机采样一个不在训练集中的 $z$，Decoder会生成无意义的垃圾数据（隐空间缺乏&amp;quot;连续性&amp;quot;和&amp;quot;分布规律&amp;quot;）。点到点的映射（像是一个&lt;strong&gt;死记硬背的学生&lt;/strong&gt;记住了全部的问题和答案（Xᵢ ↔ zᵢ），考试时只出原题就能答对（重建），但稍微变化一下题目，就完全不会了（无法生成））。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
