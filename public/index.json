[{"content":"图片 ​\t对于一张彩色图片而言，它有RGB三通道。R通道：记录图像中每个像素的红色分量强度（通常用0~255的数值表示，0表示无红色，255表示红色最亮）。G通道：记录绿色分量强度。B通道：记录蓝色分量强度。对于图片中的某一个像素而言，它有256x256x256种颜色，RGB三个通道组合而成。\n深度生成模型 ​\t文本生成，图片生成，视频生成。\n​\t对于一个输入，可以有多种，甚至无穷种回答。输出可能比输入更加复杂且高纬\n​\t一段文字转换为一个模型，模型需要进行大量的脑补。因为图片对应的文字有很多，一张图胜过千言万语。\n​\t对于文字生成而言，主要采取逐个击破（Autoregressive，自回归），从输入文本计算出最可能的下一个字或者词（计算概率，选概率最大的），然后将其追加到输入文本的末尾，作为新的输入。然后重复，直到生成结束标记；图片生成的话，也可以采取这种方式进行。要画一只奔跑的狗，计算第一个像素最可能为什么颜色（概率最大），然后将第一个像素和文字作为新的输入，重复，知道生成结束标记。太浪费时间，==现在的图像生成不使用Autorgessvie自回归！！！==\n​\timage-gpt：将2D图像转换为1D序列（得到256排的256个token），对于每一排的256个token，从输入token计算出最可能的下一个token，然后将其追加到输入token的末尾，作为新的输入。然后重复，直到生成结束标记。然后图片生成都是一排一排生成出来的。\n、\n​\t一步到位生成：直接预测256x256个每个像素点的颜色。得到的结果就是一个分布之内的，在这个分布之内的都是正确的输出。但是使用一步到位生成会导致每个像素点可能要画的图不一样（例如有的像素点是想画黑狗，有的想画白狗，有的向前跑，有的向后退，\u0026hellip;.）\n​\t为了解决这个问题，就需要使用Normal Distribution。通过Normal Distribution 得到可能的图片P(x|y)，然后文字就帮忙指导映射。\nVariational Auto-encoder(VAE) ​\t把Normal Distribution采样得到的向量放进Decoder中\nAE和VAE结构 AE（自编码器）的核心是编码-解码-重建，结构如下：\n输入：原始图像 $X$（高维数据） Encoder（编码器）：将 $X$ 降维到低维隐空间（Latent Space），得到一个确定的隐向量 $z$（$z = \\text{Encoder}(X)$） Decoder（解码器）：将隐向量 $z$ 升维，还原回高维图像 $\\hat{X}$（$\\hat{X} = \\text{Decoder}(z)$） 训练目标：最小化重建误差（比如像素级MSE），即让 $\\hat{X} \\approx X$ ​\tAE能做好降维+重建，但没法生成新数据——因为训练后，每个 $X_i$ 和 $z_i$ 是一一对应的（隐空间是\u0026quot;离散点\u0026quot;分布）。如果随机采样一个不在训练集中的 $z$，Decoder会生成无意义的垃圾数据（隐空间缺乏\u0026quot;连续性\u0026quot;和\u0026quot;分布规律\u0026quot;）。点到点的映射（像是一个死记硬背的学生记住了全部的问题和答案（Xᵢ ↔ zᵢ），考试时只出原题就能答对（重建），但稍微变化一下题目，就完全不会了（无法生成））。\n​\t核心需求：给隐空间 $z$ 加分布约束，让 $z$ 服从已知概率分布（如标准正态分布 $\\mathcal{N}(0,1)$），这样就能从该分布中随机采样 $z$，通过Decoder生成新数据。这是VAE的核心动机。\n​\tVAE（变分自编码器）保留AE的编码-解码结构，但对Encoder做关键修改，同时引入新的Loss项，解决\u0026quot;生成能力\u0026quot;问题。给隐空间加\u0026quot;分布约束\u0026quot;。分布到分布的映射（像是一个理解规律的学生，不仅记住答案，还理解了答案背后的分布规律，知道所有答案都符合某种\u0026quot;语法\u0026quot;或\u0026quot;规则\u0026quot;，即使遇到新问题，也能根据规则生成合理答案）。\nEncoder（变分编码器）：不再输出确定的 $z$，而是输出概率分布的参数——均值 $\\mu$ 和方差 $\\sigma^2$： $$\r\\mu = f_1(X), \\quad \\log\\sigma^2 = f_2(X)\r$$ 含义：对于输入 $X$，其隐向量 $z$ 不是一个点，而是服从高斯分布 $\\mathcal{N}(\\mu, \\sigma^2)$ 的随机变量。\n采样步骤：从 $\\mathcal{N}(\\mu, \\sigma^2)$ 中随机采样一个 $z$（生成能力的关键，后续用重参数化解决梯度问题）。\nDecoder（解码器）：和AE一致，输入采样得到的 $z$，输出重建图像 $\\hat{X}$，对应条件概率 $p(X|z)$（\u0026ldquo;给定 $z$，生成 $X$ 的概率\u0026rdquo;）。\nVAE的Loss VAE的Loss是重建Loss + KL散度，本质是平衡两个矛盾：\n采样的随机性会导致重建误差增大（每次采样的 $z$ 不同，$\\hat{X}$ 也不同）→ 网络倾向于让方差 $\\sigma^2 \\to 0$（退化成AE，失去生成能力）。 需要 $z$ 服从标准正态分布 $\\mathcal{N}(0,1)$（保证隐空间连续性，方便采样生成）→ 必须约束 $\\mathcal{N}(\\mu, \\sigma^2)$ 贴近 $\\mathcal{N}(0,1)$。 首先给出完整的VAE损失函数（对于单个样本$X$）： $$\r\\mathcal{Loss}_{\\text{VAE}}(\\theta, \\phi; X) = \\underbrace{\\mathbb{E}_{q_\\phi(z|X)}[\\log p_\\theta(X|z)]}_{\\text{重建Loss}} - \\beta \\cdot \\underbrace{D_{\\text{KL}}(q_\\phi(z|X) \\parallel p(z))}_{\\text{KL散度正则项约束}}\r$$ $X$ 观测数据（输入） 向量 $\\mathbb{R}^D$ 例如：一张$28×28$的MNIST图像展平为$784$维向量 $z$ 隐变量 向量 $\\mathbb{R}^d$ 潜在表示，$d \\ll D$（如$d=20$） $\\theta$ 解码器参数 神经网络权重 解码器$p_\\theta(x $\\phi$ 编码器参数 神经网络权重 编码器$q_\\phi(z $\\beta$ 正则化系数 标量 $\\mathbb{R}^+$ 控制KL散度的权重，$\\beta=1$时为标准VAE 第一项 $\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]= \\int \\log p_\\theta(x|z) \\cdot q_\\phi(z|x) dz$ （重建Loss）\n和AE一致，让 $\\hat{X}$($\\hat{X}=\\log p(X|z) \\approx X$)越大，重建效果越好。从编码器分布$q_\\phi(z|x)$中采样多个$z$，对每个$z$计算$\\log p_\\theta(x|z)$（重建质量），然后取平均值。 $q_\\phi(z|X)$：变分后验分布，给定$X$时，$z$的近似后验分布，编码器建模。多元高斯分布$$q_\\phi(z|X) = \\mathcal{N}(z; \\mu_\\phi(X), \\text{diag}(\\sigma^2_\\phi(X)))$$ 编码器输出两个向量：$\\mu_\\phi(x) \\in \\mathbb{R}^d$均值向量，$\\log\\sigma^2_\\phi(x) \\in \\mathbb{R}^d$对数方差向量 $\\log p_\\theta(X|z)$：**对数条件似然函数 **（在给定$z$的条件下，数据$X$出现的\u0026quot;可能性\u0026quot;的对数，越大表示重建效果越好） $p_\\theta(x|z)$：条件似然函数（给定隐变量$z$时，生成观测数据$X$的概率，由解码器建模），为二值数据或者连续数据 二值数据（如MNIST二值图）：伯努利分布$$p_\\theta(X|z) = \\prod_{i=1}^D [\\pi_i(z)]^{x_i}[1-\\pi_i(z)]^{1-x_i}$$，其中$\\pi_i(z) \\in [0,1]$是解码器第$i$个输出（sigmoid激活）。$$\\log p_\\theta(X|z) = \\sum_{i=1}^D [X_i \\log \\pi_i(z) + (1-X_i)\\log(1-\\pi_i(z))]$$，这就是交叉熵损失！ 连续数据（如灰度图）：高斯分布$$p_\\theta(X|z) = \\prod_{i=1}^D \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(X_i - \\mu_i(z))^2}{2\\sigma^2}\\right)$$, 通常固定$\\sigma=1$，解码器输出均值$\\mu(z)$。$$\\log p_\\theta(X|z) = -\\frac{1}{2}\\sum_{i=1}^D (X_i - \\mu_i(z))^2 + \\text{常数}$$，这就是均方误差（MSE） 的负值！ 第二项 $D_{\\text{KL}}(q_\\phi(z|x) \\parallel p(z))$（KL散度）：\nKL散度定义：$ D_{\\text{KL}}(q \\parallel p) = \\int q(z) \\log\\frac{q(z)}{p(z)} dz $，衡量两个概率分布$q$和$p$之间的\u0026quot;差异\u0026quot;或\u0026quot;距离\u0026quot;。 衡量解码器输出分布 $q(z|X) = \\mathcal{N}(\\mu, \\sigma^2)$ 与目标先验分布 $p(z) = \\mathcal{N}(0,1)$ 差距，KL越小分布越近，隐空间越符合正态分布。 $q_\\phi(z|x) = \\mathcal{N}(z; \\mu, \\text{diag}(\\sigma^2))$：编码器输出的分布，其中$\\mu = \\mu_\\phi(x)$，$\\sigma^2 = \\sigma^2_\\phi(x)$ $p(z) = \\mathcal{N}(z; 0, I)$：先验分布，标准多元正态分布 负号：最大化重建（$\\log p(X|z)$ 越大越好）+ 最小化KL散度，合并后为\u0026quot;重建项-KL项\u0026quot;，整体目标是最大化Loss/最小化其负值。\nELBO 生成模型的终极目标是学习数据的真实分布 $p(X)$——只要学到 $p(X)$，就能从该分布中采样生成新数据。\n但直接估计 $p(X)$ 极难（如图像数据分布复杂，无简单公式描述），因此VAE引入隐变量 $z$，将 $p(X)$ 分解为： $$\rp(X) = \\int p(X|z) p(z) dz\r$$ 含义：数据 $X$ 的生成过程是\u0026quot;先从先验分布 $p(z)$ 采样 $z$，再从条件分布 $p(X|z)$ 采样 $X$\u0026quot; 问题：高维隐空间的积分是NP难的，无法直接计算 为解决积分难题，VAE采用变分推断：引入可参数化的近似后验分布 $q(z|X)$（即Encoder输出的 $\\mathcal{N}(\\mu, \\sigma^2)$），用它近似无法计算的真实后验 $p(z|X)$（\u0026ldquo;给定 $X$，隐变量 $z$ 的真实分布\u0026rdquo;）。\n衡量两个分布相似度的指标是KL散度：$KL(q(z|X) \\parallel p(z|X)) \\geq 0$（KL散度永远非负，等于0时两个分布完全一致）。\n目标是最大化对数似然 $\\log p(X)$（极大似然估计，让模型生成真实数据的概率最大）。通过数学变形，可将 $\\log p(X)$ 拆分为ELBO + KL散度： $$\r\\begin{aligned}\r\\log p(X) \u0026= \\mathbb{E}_{q(z|X)}[\\log p(X)] \\quad (\\text{乘以} \\int q(z|X)dz=1\\text{，不改变结果}) \\\\\r\u0026= \\mathbb{E}_{q(z|X)}\\left[\\log \\frac{p(X,z)}{p(z|X)}\\right] \\quad (\\text{贝叶斯公式：} p(X,z)=p(X|z)p(z)=p(z|X)p(X)) \\\\\r\u0026= \\mathbb{E}_{q(z|X)}\\left[\\log \\frac{p(X,z) q(z|X)}{p(z|X) q(z|X)}\\right] \\quad (\\text{分子分母同乘} q(z|X)) \\\\\r\u0026= \\underbrace{\\mathbb{E}_{q(z|X)}\\left[\\log \\frac{p(X,z)}{q(z|X)}\\right]}_{\\text{ELBO}} + \\underbrace{KL(q(z|X) \\parallel p(z|X))}_{\\geq 0}\r\\end{aligned}\r$$因 $KL(q \\parallel p) \\geq 0$，故： $$\r\\log p(X) \\geq \\text{ELBO}\r$$ $\\log p(X)$ 是模型证据（Model Evidence），衡量模型对数据的拟合程度 ELBO是证据下界（Evidence Lower Bound）——它是 $\\log p(X)$ 的下界，最大化ELBO等价于最大化 $\\log p(X)$（当KL=0时，ELBO=log p(X)） 对ELBO进一步变形，可得VAE的Loss： $$\r\\begin{aligned}\r\\text{ELBO} \u0026= \\mathbb{E}_{q(z|X)}\\left[\\log \\frac{p(X,z)}{q(z|X)}\\right] \\\\\r\u0026= \\mathbb{E}_{q(z|X)}\\left[\\log \\frac{p(X|z) p(z)}{q(z|X)}\\right] \\quad (\\text{分解联合分布} p(X,z)=p(X|z)p(z)) \\\\\r\u0026= \\mathbb{E}_{q(z|X)}[\\log p(X|z)] + \\mathbb{E}_{q(z|X)}\\left[\\log \\frac{p(z)}{q(z|X)}\\right] \\\\\r\u0026= \\mathbb{E}_{q(z|X)}[\\log p(X|z)] - KL(q(z|X) \\parallel p(z))\r\\end{aligned}\r$$这与之前的VAE Loss完全一致！\n结论：VAE的训练目标最大化ELBO，本质是通过近似后验 $q(z|X)$ 间接最大化模型证据 $\\log p(X)$，既保证重建效果，又约束隐空间分布，从而获得生成能力。\nFlow-based Generative Model ​\t很多照片输入，输出是Normal Distribution\nGenerative Adversarial Network(GAN) Diffusion Model ","permalink":"http://localhost:1313/posts/2026/01/%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/","summary":"\u003ch1 id=\"图片\"\u003e图片\u003c/h1\u003e\n\u003cp\u003e​\t对于一张彩色图片而言，它有RGB三通道。\u003cstrong\u003eR通道\u003c/strong\u003e：记录图像中每个像素的\u003cstrong\u003e红色分量强度\u003c/strong\u003e（通常用0~255的数值表示，0表示无红色，255表示红色最亮）。\u003cstrong\u003eG通道\u003c/strong\u003e：记录\u003cstrong\u003e绿色分量强度\u003c/strong\u003e。\u003cstrong\u003eB通道\u003c/strong\u003e：记录\u003cstrong\u003e蓝色分量强度\u003c/strong\u003e。对于图片中的某一个像素而言，它有256x256x256种颜色，RGB三个通道组合而成。\u003c/p\u003e\n\u003ch1 id=\"深度生成模型\"\u003e深度生成模型\u003c/h1\u003e\n\u003cp\u003e​\t文本生成，图片生成，视频生成。\u003c/p\u003e\n\u003cp\u003e​\t对于一个输入，可以有多种，甚至无穷种回答。输出可能比输入更加复杂且高纬\u003c/p\u003e\n\u003cp\u003e​\t一段文字转换为一个模型，模型需要进行大量的脑补。因为图片对应的文字有很多，一张图胜过千言万语。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20251222152235572\" loading=\"lazy\" src=\"/posts/2026/01/%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/index.assets/image-20251222152235572.png\"\u003e\u003c/p\u003e\n\u003cp\u003e​\t对于文字生成而言，主要采取逐个击破（Autoregressive，自回归），从输入文本计算出最可能的下一个字或者词（计算概率，选概率最大的），然后将其追加到输入文本的末尾，作为新的输入。然后重复，直到生成结束标记；图片生成的话，也可以采取这种方式进行。要画一只奔跑的狗，计算第一个像素最可能为什么颜色（概率最大），然后将第一个像素和文字作为新的输入，重复，知道生成结束标记。太浪费时间，==现在的图像生成不使用Autorgessvie自回归！！！==\u003c/p\u003e\n\u003cp\u003e​\timage-gpt：将2D图像转换为1D序列（得到256排的256个token），对于每一排的256个token，从输入token计算出最可能的下一个token，然后将其追加到输入token的末尾，作为新的输入。然后重复，直到生成结束标记。然后\u003cstrong\u003e图片生成都是一排一排生成出来的\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"./index.assets/image-20251222153436840.png\" alt=\"image-20251222153436840\" style=\"zoom:25%;\" /\u003e\u003cimg src=\"./../../../../Study/%25E6%25B7%25B1%25E5%25BA%25A6%25E7%2594%259F%25E6%2588%2590%25E6%25A8%25A1%25E5%259E%258B/%25E6%25B7%25B1%25E5%25BA%25A6%25E7%2594%259F%25E6%2588%2590%25E6%25A8%25A1%25E5%259E%258B.assets/image-20251222153534658.png\" alt=\"image-20251222153534658\" style=\"zoom:25%;\" /\u003e、\u003c/p\u003e\n\u003cp\u003e​\t一步到位生成：直接预测256x256个每个像素点的颜色。得到的结果就是一个分布之内的，在这个分布之内的都是正确的输出。但是使用一步到位生成会导致每个像素点可能要画的图不一样（例如有的像素点是想画黑狗，有的想画白狗，有的向前跑，有的向后退，\u0026hellip;.）\u003c/p\u003e\n\u003cimg src=\"./index.assets/image-20251222164736119.png\" alt=\"image-20251222164736119\" style=\"zoom: 67%;\" /\u003e\r\n\u003cp\u003e​\t为了解决这个问题，就需要使用Normal Distribution。通过Normal Distribution 得到可能的图片P(x|y)，然后文字就帮忙指导映射。\u003c/p\u003e\n\u003cimg src=\"./index.assets/image-20251222165314430.png\" alt=\"image-20251222165314430\" style=\"zoom: 67%;\" /\u003e\r\n\u003ch1 id=\"variational-auto-encodervae\"\u003eVariational Auto-encoder(VAE)\u003c/h1\u003e\n\u003cp\u003e​\t把Normal Distribution采样得到的向量放进Decoder中\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20251222170720742\" loading=\"lazy\" src=\"/posts/2026/01/%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/index.assets/image-20251222170720742.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"ae和vae结构\"\u003eAE和VAE结构\u003c/h2\u003e\n\u003cp\u003eAE（自编码器）的核心是\u003cstrong\u003e编码-解码-重建\u003c/strong\u003e，结构如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e输入\u003c/strong\u003e：原始图像 $X$（高维数据）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEncoder（编码器）\u003c/strong\u003e：将 $X$ 降维到低维隐空间（Latent Space），得到一个确定的隐向量 $z$（$z = \\text{Encoder}(X)$）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDecoder（解码器）\u003c/strong\u003e：将隐向量 $z$ 升维，还原回高维图像 $\\hat{X}$（$\\hat{X} = \\text{Decoder}(z)$）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e训练目标\u003c/strong\u003e：最小化\u003cstrong\u003e重建误差\u003c/strong\u003e（比如像素级MSE），即让 $\\hat{X} \\approx X$\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e​\tAE能做好\u003cstrong\u003e降维+重建\u003c/strong\u003e，但没法\u003cstrong\u003e生成新数据\u003c/strong\u003e——因为训练后，每个 $X_i$ 和 $z_i$ 是\u003cstrong\u003e一一对应\u003c/strong\u003e的（隐空间是\u0026quot;离散点\u0026quot;分布）。如果随机采样一个不在训练集中的 $z$，Decoder会生成无意义的垃圾数据（隐空间缺乏\u0026quot;连续性\u0026quot;和\u0026quot;分布规律\u0026quot;）。点到点的映射（像是一个\u003cstrong\u003e死记硬背的学生\u003c/strong\u003e记住了全部的问题和答案（Xᵢ ↔ zᵢ），考试时只出原题就能答对（重建），但稍微变化一下题目，就完全不会了（无法生成））。\u003c/p\u003e\n\u003cp\u003e​\t\u003cstrong\u003e核心需求\u003c/strong\u003e：给隐空间 $z$ 加\u003cstrong\u003e分布约束\u003c/strong\u003e，让 $z$ 服从已知概率分布（如标准正态分布 $\\mathcal{N}(0,1)$），这样就能从该分布中随机采样 $z$，通过Decoder生成新数据。这是VAE的核心动机。\u003c/p\u003e","title":"深度生成模型"},{"content":"Hugo搭建个人博客 Hexo和Hugo对比 Hexo (基于 Node.js): 原理： 它是用 JavaScript 写的，依赖庞大的 node_modules 库。 痛点： “偶尔使用”，如果今天搭好了 Hexo，过了半年想写篇新文章，再次打开时，很可能因为 Node.js 版本更新、某个插件作者弃坑、或者依赖包冲突，导致直接报错运行不起来。 现象： 著名的“依赖地狱”。为了修好它，可能需要花一整天折腾环境，而不是写文章。 编译速度：Hexo随着文章数量增加（比如写了100篇笔记），生成一次静态网站可能需要几十秒甚至几分钟。 代码块和数学公式：Hexo原生对数学公式（LaTeX）支持较差。通常需要安装第三方渲染插件（如 hexo-renderer-pandoc 或 hexo-math），这些插件的配置非常繁琐，经常出现公式渲染不出来、和 Markdown 语法冲突的问题（比如下划线 _ 被转义）。 主题风格：Hexo 的生态比较偏向“二次元”、“花哨”、“社交化”。著名的 Next、Butterfly 主题功能极其强大，有很多动画特效、看板娘、复杂的侧边栏。这不符合想要的“简约、学术”风格。 Hugo (基于 Go 语言): 原理： 它就是一个单一的二进制文件 (hugo.exe)。 优势： 不需要安装任何依赖库。无论过了多久，只要这个 exe 文件还在，博客就能生成。极其稳定，零维护成本。 编译速度：Hugo是目前世界上最快的静态网站生成器。生成几百篇文章通常只需要 几毫秒到几秒。这种“修改即预览”的快感，对写作体验的提升是巨大的。 代码块和数学公式： Hugo虽然原生也需要配置，但 PaperMod 主题，已经内置了对 MathJax/KaTeX 的完美支持。只需要在配置文件里把 math: true 打开，就能直接写公式，非常省心。 主题风格：Hugo 的生态比较偏向“极客”、“技术文档”、“学术”。PaperMod、MemE 等主题都非常克制，排版干净，加载速度极快，非常适合阅读长篇的技术笔记。 特性 Hexo Hugo (推荐) 安装难度 繁琐 (需装 Node.js, Git, npm install\u0026hellip;) 极简 (仅需下载一个 exe 文件) 稳定性 差 (依赖包容易过时报错，几个月不用容易崩) 极高 (几乎不会坏) 生成速度 较慢 (文章多了会卡) 飞快 (闪电般的速度) 主要风格 华丽、二次元、功能堆砌 简约、学术、注重内容 数学公式 需折腾插件，容易出错 主题配合好，配置简单 Hugo介绍 Hugo 非常灵活，它的扩展性其实比 Hexo 更强，因为它允许你完全控制生成的 HTML 代码。只是它的“玩法”和 Hexo 稍微有点不一样。对于“偶尔使用 HTML/CSS”的情况，Hugo 其实更友好，因为它的逻辑很清晰。\n1. 初级玩法：微调样式 (颜色、字体、间距) 如果觉得 PaperMod 默认的黑色/白色不够看，或者想改一下字号。\n怎么做： 不需要改动主题源代码。Hugo 有一个**“覆盖机制”**。 具体操作： 在博客根目录下创建一个文件 assets/css/extended/custom.css (如果没有这个文件夹就自己建)。 效果： 在这个文件里写的任何 CSS，都会自动覆盖掉主题的默认设置。 比如：想把标题改成红色？就在 custom.css 里写个 .post-title { color: red; } 就行了。 2. 中级玩法：加特效 (背景动画、点击爆炸效果、鼠标跟随) “特效”本质上就是 JavaScript 代码。\n怎么做： PaperMod 主题预留了接口能够插入这些代码。 具体操作： 在博客根目录下创建 layouts/partials/extend_head.html 或 extend_footer.html。 效果： 把网上的特效代码（比如“看板娘”、“粒子背景”、“鼠标点击爱心”）复制粘贴到这个文件里，它们就会出现在网站上。 比如：想加一个学术风的动态背景，只需要找一个 particles.js 的库，把引用代码贴进去即可。 3. 高级玩法：自定义组件 (Shortcodes) 博客侧重“学习笔记、数学公式、图表”。Hugo 有一个超强功能叫 Shortcodes (短代码)。\n场景： 假设不仅想贴图片，还想在文章里直接插入一个“B站视频”、“网易云音乐播放器”或者“交互式数学图表”。 怎么做： 可以写一个简单的模板文件。 总结与对比 Hexo: 很多特效靠“安装插件”（npm install）。优点是傻瓜式，缺点是插件容易冲突，且容易把网站拖慢。 Hugo: 特效靠“复制粘贴”代码到指定位置。优点是清楚地知道加了什么，不会莫名其妙报错，且因为没有冗余代码，网站依然飞快。 选择了 Hugo + PaperMod 只是打了一个最稳固、最干净的地基。等地基打好了，随时可以用 CSS 给墙面刷漆（改样式），或者用 JS 给屋里添置智能家电（加特效）。而且因为地基好，无论怎么装修，房子都不会塌（报错）。 软件安装 第一步：安装编辑器 (VS Code) 这是我们以后用来写文章的工具，像 Word 一样，但更适合写代码。\n下载： 点击这里 VS Code 官网下载。 安装： 下载后双击安装包。 注意： 安装过程中，如果有看到“添加到右键菜单”或者“Open with Code”的选项，请务必全部勾选（这以后会很方便）。其他的一路点击“下一步”即可。 第二步：安装 Git 这是用来把您的文章传到网上的工具。\n下载： 点击这里 Git 官网下载。 安装： 也就是一路点击“Next”（下一步），不用修改任何默认设置，直到安装完成。 第三步：安装 Hugo (这是最关键的一步) 这个步骤稍微有点不一样，请仔细看：\n1. 下载 Hugo (Extended 版本)\n点击这个链接进入下载页：Hugo Releases (GitHub) 往下滑，找到 Assets 区域。 一定要找带 extended 字样的版本！ Windows 用户请下载：hugo_extended_0.154.0_windows-amd64.zip (版本号可能更高，没关系)。 注意：不要下载那个不带 extended 的，也不要下 linux/darwin 的。 2. 解压与放置\n把下载好的压缩包解压。 你会看到一个 hugo.exe 文件。 在您的 C盘 创建一个文件夹，命名为 Hugo。 在 Hugo 文件夹里再建一个文件夹，叫 bin。 把 hugo.exe 扔进去。 现在的路径应该是：C:\\Hugo\\bin\\hugo.exe 3. 配置环境变量 (让电脑认识 Hugo) 这一步如果不做，电脑会说“找不到 hugo 命令”。\n按键盘上的 Win 键 (微软徽标键)，直接输入搜索：环境变量。 选择 “编辑系统环境变量”。 点击右下角的 “环境变量” 按钮。 在上面的框（用户变量）或者下面的框（系统变量）里，找到一行叫 Path 的文字，选中它，点击 “编辑”。 点击右边的 “新建”。 输入刚才存放 hugo 的路径：D:\\Software\\Hugo\\bin 连续点击“确定”，直到所有窗口关闭。 第四步：验证一下是否成功 做完上面三步后，请测试一下：\n按 Win + R 键，输入 cmd，回车打开黑色窗口。 输入命令：hugo version 如果出现一行类似 hugo v0.154.0-0b71db299a2bd89be876d7dc972ded03a222f560+extended windows/amd64 BuildDate=2025-12-31T12:45:55Z VendorInfo=gohugoio的字，说明大功告成！ 创建博客 第一步：简单的 Git 身份设置 我“偶尔使用”Git，为了防止一会儿提交时报错，我们先告诉电脑“我是谁”。\n在刚才那个黑色窗口（cmd）里，依次输入下面两行命令（把引号里的内容修改）：\n1 2 git config --global user.name \u0026#34;RisingInsight\u0026#34; git config --global user.email \u0026#34;1668676243@qq.com\u0026#34; 第二步：在 GitHub 创建“专用”仓库 这是博客在互联网上的“家”。\n登录 GitHub。 点击页面右上角的 + 号，选择 New repository。 Repository name (仓库名)： 【非常关键，请仔细看】 这个名字必须完全符合这个格式：用户名.github.io 比如：我的 GitHub 用户名是 RisingInsight，仓库名就必须填 RisingInsight.github.io。如果填错了，博客就无法直接访问。 Public/Private： 选 Public (公开)。 其他都不用管，直接点最下面的绿色按钮 Create repository。 创建好后，不要关掉那个网页，一会儿我们要用里面的链接。 第三步：在本地创建博客文件夹 现在回到电脑。为了管理方便，建议不要放在 C 盘深处。\n在电脑上找个风水宝地（比如 D盘 或者 桌面），新建一个文件夹，命名为 MyBlog。 进入这个 Blog 文件夹。 在这里打开终端： 在文件夹空白处右键 -\u0026gt; 选择 \u0026ldquo;Open in Terminal\u0026rdquo; (在终端打开)。 现在应该看到了黑色窗口，且路径是在 Blog 下面。依次复制粘贴执行以下命令：\n1. 生成博客骨架\n1 hugo new site . -f yaml (注意：site 后面有个空格，然后有个点 .，这表示“就在当前目录创建”。)\n2. 初始化 Git 并关联 GitHub\n1 2 git init git branch -M main 3. 关联远程仓库 还记得刚才 GitHub 网页上创建好的仓库吗？\n复制那个网页里的 HTTPS 链接（通常是以 https://github.com/\u0026hellip; 结尾的）。 回到黑色窗口，输入下面的命令（把地址换成自己的）： 1 git remote add origin https://github.com/RisingInsight/RisingInsight.github.io 第四步：安装 PaperMod 主题 我们要用最干净、学术风的主题 PaperMod。在黑色窗口继续输入：\n1 git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod 验证一下 做完以上步骤后，请打开文件夹 Blog，应该能看到：\n一个 themes 文件夹（里面有 PaperMod）。 一个 hugo.yaml 文件。 以及 content, layouts 等文件夹。 如果都看到了，请回复我“就位”，我们就进入最好玩的环节：配置属于您的界面！\n上传到GIthub 第一步：检查“自动化部署脚本” (GitHub Actions) 这是最关键的一步。如果没有这个文件，您把代码推上去也只是“存了个网盘”，网站不会自动上线。\n检查文件是否存在： 在 VS Code 左侧文件列表，看看有没有一个叫 .github 的文件夹（注意前面有个点）。 里面有没有 workflows 文件夹。 里面有没有一个 .yaml 文件（比如 hugo.yaml 或 deploy.yaml）。 如果没有（或者不确定对不对），请重新建一个： 在根目录新建文件夹：.github 在里面新建文件夹：workflows 在 workflows 里新建文件：deploy.yaml (为了和根目录的配置文件区分开，我们叫它 deploy)。 复制粘贴以下内容（这是适配您当前环境的标准自动化脚本）： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 # GitHub Actions 自动构建部署脚本 name: Deploy Hugo site to Pages on: # 每次推送到 main 分支时触发 push: branches: [\u0026#34;main\u0026#34;] # 允许手动在 GitHub 页面触发 workflow_dispatch: # 设置权限 permissions: contents: read pages: write id-token: write # 并发控制 concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false defaults: run: shell: bash jobs: # 构建任务 build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.121.1 # 指定 Hugo 版本 HUGO_ENV: production steps: - name: Checkout 代码 uses: actions/checkout@v4 with: submodules: recursive # 必须递归下载主题 - name: 安装 Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; extended: true # 必须使用 extended 版本 - name: 开始构建 run: hugo --minify - name: 上传构建产物 uses: actions/upload-pages-artifact@v3 with: path: ./public # 部署任务 deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: 部署到 GitHub Pages id: deployment uses: actions/deploy-pages@v4 保存文件。\n第二步：推送代码 (Git Push) 现在把所有的文件（配置、图片、文章、特效代码）一次性打包发给 GitHub。\n回到 VS Code 下方的终端。 依次输入以下命令（每输一行按一次回车）： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 1. 把所有修改放入暂存区 git add . # 2. 提交修改 (引号里写备注，比如 \u0026#34;博客最终版上线\u0026#34;) git commit -m \u0026#34;complete blog setup\u0026#34; # 3. 推送到 GitHub (确保您的分支名是 main) git push -u origin main # 4. 拉取远程仓库的最新代码 (Git Pull) git pull origin main --rebase # 5. 再次推送本地代码 (Git Push) git push -u origin main 如果第 3 步报错说 src refspec main does not match any，请试一下 git push -u origin master。如果还不行，截图给我。\n第三步：去 GitHub 开启“开关” (最后一步) 代码推上去后，我们需要告诉 GitHub：“请用 Actions 来发布我的网站”。\n打开浏览器，登录您的 GitHub 仓库页面。 点击上方的 Settings (设置) 选项卡。 在左侧边栏，找到并点击 Pages。 看右边的 Build and deployment 区域： Source (来源)：请选择 GitHub Actions。 (原本可能是 Deploy from a branch，一定要改成 GitHub Actions)。 修改完设置后，GitHub 可能不会立刻更新，我们需要手动触发一次更新，或者等待它自动反应。 点击顶部导航栏的 Actions。 您应该能看到左侧有一个 Deploy Hugo site to Pages。 点击它，查看右侧列表。 如果有一个正在转圈的任务，请等待它变成绿色对钩。 如果没有正在运行的任务，或者上一个任务是红色的（失败），我们需要手动触发一次： 点击列表里最新的那次记录。 右上角通常有个 Re-run jobs 按钮，点击它重新运行。 成功后的验证： Git 终端： 看到类似 To https://github.com/RisingInsight/RisingInsight.github.io 和 main -\u0026gt; main 的字样，没有 [rejected] 就说明成功了。 GitHub Actions： 登录您的 GitHub 仓库页面。 点击上方的 Actions 选项卡。 您应该会看到一个新的 GitHub Actions 任务正在运行（或者已经完成）。它会显示您刚刚提交的信息 complete blog setup。 等待这个任务变成绿色的对钩 (✅)。 博客上线： 任务成功后，回到 Settings -\u0026gt; Pages。 查看您的博客网址 https://RisingInsight.github.io/ 是否已经更新，所有美化和功能是否都上线了。 美化 放弃CSS、直接完全使用HTML\n绕开 CSS 加载问题，直接在各个模块写内联样式\n后续更新 更新本地博客代码到 GitHub 仓库的核心是「Git 提交 + 推送」，以下是分步详细操作（适配新手，覆盖所有常见场景）：\n前提准备 确认本地已安装 Git（打开 PowerShell 执行 git --version，有版本号则已安装；无则下载：https://git-scm.com/download/win）； 确认本地博客目录已关联 GitHub 仓库（执行 git remote -v，能看到 GitHub 仓库地址则已关联；无则先关联，见「补充场景 1」）； 已登录 GitHub 账号（推荐用「个人访问令牌（PAT）」或 SSH 密钥认证，避免密码登录失效）。 核心步骤（PowerShell 操作，在博客根目录 E:\\Blog 执行） 步骤 1：进入博客根目录 1 2 cd E:\\Blog # 切换到博客根目录（你的目录路径） hugo server --ignoreCache --disableFastRender --cleanDestinationDir 步骤 2：检查修改的文件（确认要提交的内容） 1 git status 会列出所有修改 / 新增的文件（比如 layouts/partials/footer.html、assets/css/extended.css 等），确认是你要提交的内容。\n步骤 3：暂存所有修改（把文件加入提交队列） 1 git add . # 「.」代表暂存所有修改/新增文件；若只想暂存单个文件，比如 git add layouts/partials/footer.html 步骤 4：提交修改（写提交说明，记录改动） 执行（替换提交信息为自己的描述，比如「更新分页样式 + 自定义页脚版权」）：\n1 git commit -m \u0026#34;更新博客：分页样式居中+页脚版权改为2026.1.1~至今\u0026#34; ✅ 提交信息建议清晰，比如：\n改样式：优化分页样式，实现数字居中 改页脚：自定义页脚版权时间为2026.1.1~动态日期 综合修改：更新分页样式+页脚版权信息 步骤 5：推送到 GitHub 仓库 执行（默认分支是 main，如果你的仓库分支是 master，替换为 master）：\n1 git push origin main 首次推送 / 认证失败：参考「补充场景 1/2」解决； 推送成功：打开 GitHub 仓库页面，能看到最新的提交记录和修改后的文件。 补充场景（解决常见问题） 场景 1：本地目录未关联 GitHub 仓库（首次推送） 先在 GitHub 新建一个空仓库（比如命名为 blog，不要勾选「Add a README file」）；\n回到本地 PowerShell，执行（替换为你的 GitHub 仓库地址）：\n1 2 3 4 5 6 # 初始化本地仓库（仅首次执行） git init # 关联远程 GitHub 仓库（替换为你的仓库地址，HTTPS/SSH 均可） git remote add origin https://github.com/你的GitHub用户名/你的仓库名.git # 首次推送需设置上游分支 git push -u origin main 场景 2：推送时提示「认证失败」（GitHub 不再支持密码登录） 解决方法：用「个人访问令牌（PAT）」登录：\n生成 PAT：GitHub 官网 → 头像 → Settings → Developer settings → Personal access tokens → Generate new token（勾选 repo 权限，保存令牌）；\n推送时，用户名填 GitHub 账号，密码填生成的 PAT；\n✅ 更便捷的方式：配置 SSH 密钥（参考 GitHub 文档：\nhttps://docs.github.com/zh/authentication/connecting-to-github-with-ssh\n）。\n场景 3：推送时提示「本地分支落后于远程」 先拉取远程最新代码，再推送：\n1 2 git pull origin main # 拉取远程main分支 git push origin main # 再推送 验证是否成功 打开 GitHub 仓库页面（https://github.com/你的用户名 / 你的仓库名）：\n能看到最新的「Commit」记录（和你写的提交信息一致）； 点击对应文件（比如 layouts/partials/footer.html），能看到修改后的代码； 若博客是「GitHub Pages」部署，推送后等待几分钟，访问 Pages 地址能看到修改后的效果。 简化操作（后续更新可一键执行） 把步骤 2-5 合并为：\n1 2 3 4 cd E:\\Blog git add . git commit -m \u0026#34;你的提交信息\u0026#34; git push origin main 每次修改后，执行这 4 行即可快速更新到 GitHub。\n","permalink":"http://localhost:1313/posts/2026/01/hugo%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","summary":"\u003ch1 id=\"hugo搭建个人博客\"\u003eHugo搭建个人博客\u003c/h1\u003e\n\u003ch2 id=\"hexo和hugo对比\"\u003eHexo和Hugo对比\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eHexo (基于 Node.js):\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e原理：\u003c/strong\u003e 它是用 JavaScript 写的，依赖庞大的 node_modules 库。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e痛点：\u003c/strong\u003e “偶尔使用”，如果今天搭好了 Hexo，过了半年想写篇新文章，再次打开时，很可能因为 Node.js 版本更新、某个插件作者弃坑、或者依赖包冲突，导致\u003cstrong\u003e直接报错运行不起来\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e现象：\u003c/strong\u003e 著名的“依赖地狱”。为了修好它，可能需要花一整天折腾环境，而不是写文章。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e编译速度\u003c/strong\u003e：Hexo随着文章数量增加（比如写了100篇笔记），生成一次静态网站可能需要几十秒甚至几分钟。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代码块和数学公式\u003c/strong\u003e：Hexo原生对数学公式（LaTeX）支持较差。通常需要安装第三方渲染插件（如 hexo-renderer-pandoc 或 hexo-math），这些插件的配置非常繁琐，经常出现公式渲染不出来、和 Markdown 语法冲突的问题（比如下划线 _ 被转义）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e主题风格\u003c/strong\u003e：Hexo 的生态比较偏向“二次元”、“花哨”、“社交化”。著名的 Next、Butterfly 主题功能极其强大，有很多动画特效、看板娘、复杂的侧边栏。这\u003cstrong\u003e不符合\u003c/strong\u003e想要的“简约、学术”风格。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHugo (基于 Go 语言):\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e原理：\u003c/strong\u003e 它就是一个\u003cstrong\u003e单一的二进制文件\u003c/strong\u003e (hugo.exe)。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e优势：\u003c/strong\u003e 不需要安装任何依赖库。无论过了多久，只要这个 exe 文件还在，博客就能生成。\u003cstrong\u003e极其稳定，零维护成本\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e编译速度\u003c/strong\u003e：Hugo是目前世界上最快的静态网站生成器。生成几百篇文章通常只需要 \u003cstrong\u003e几毫秒到几秒\u003c/strong\u003e。这种“修改即预览”的快感，对写作体验的提升是巨大的。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代码块和数学公式\u003c/strong\u003e： Hugo虽然原生也需要配置，但 \u003cstrong\u003ePaperMod\u003c/strong\u003e 主题，已经\u003cstrong\u003e内置\u003c/strong\u003e了对 MathJax/KaTeX 的完美支持。只需要在配置文件里把 math: true 打开，就能直接写公式，非常省心。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e主题风格\u003c/strong\u003e：Hugo 的生态比较偏向“极客”、“技术文档”、“学术”。PaperMod、MemE 等主题都非常克制，排版干净，加载速度极快，非常适合阅读长篇的技术笔记。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e特性\u003c/th\u003e\n          \u003cth\u003eHexo\u003c/th\u003e\n          \u003cth\u003eHugo (推荐)\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e安装难度\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e繁琐 (需装 Node.js, Git, npm install\u0026hellip;)\u003c/td\u003e\n          \u003ctd\u003e\u003cstrong\u003e极简 (仅需下载一个 exe 文件)\u003c/strong\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e稳定性\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e差 (依赖包容易过时报错，几个月不用容易崩)\u003c/td\u003e\n          \u003ctd\u003e\u003cstrong\u003e极高 (几乎不会坏)\u003c/strong\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e生成速度\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e较慢 (文章多了会卡)\u003c/td\u003e\n          \u003ctd\u003e\u003cstrong\u003e飞快 (闪电般的速度)\u003c/strong\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e主要风格\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e华丽、二次元、功能堆砌\u003c/td\u003e\n          \u003ctd\u003e\u003cstrong\u003e简约、学术、注重内容\u003c/strong\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e数学公式\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e需折腾插件，容易出错\u003c/td\u003e\n          \u003ctd\u003e\u003cstrong\u003e主题配合好，配置简单\u003c/strong\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"hugo介绍\"\u003eHugo介绍\u003c/h2\u003e\n\u003cp\u003eHugo 非常灵活，它的扩展性其实比 Hexo 更强，因为它允许你完全控制生成的 HTML 代码。只是它的“玩法”和 Hexo 稍微有点不一样。对于“偶尔使用 HTML/CSS”的情况，Hugo 其实更友好，因为它的逻辑很清晰。\u003c/p\u003e","title":"Hugo使用教程"},{"content":"1. 数学公式测试 (MathJax) 行内公式： 我们要计算 $E = mc^2$ 的能量。\n块级公式： 这是一个高斯积分： $$\r\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}\r$$2. 代码块测试 1 2 3 4 5 6 def fib(n): if n \u0026lt;= 1: return n return fib(n-1) + fib(n-2) print(fib(10)) ","permalink":"http://localhost:1313/posts/2026/01/%E5%85%AC%E5%BC%8F%E5%92%8C%E4%BB%A3%E7%A0%81%E6%B5%8B%E8%AF%95/","summary":"\u003ch2 id=\"1-数学公式测试-mathjax\"\u003e1. 数学公式测试 (MathJax)\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e行内公式：\u003c/strong\u003e\n我们要计算 $E = mc^2$ 的能量。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e块级公式：\u003c/strong\u003e\n这是一个高斯积分：\n\u003c/p\u003e\n$$\r\n\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}\r\n$$\u003ch2 id=\"2-代码块测试\"\u003e2. 代码块测试\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\" id=\"hl-0-1\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-1\"\u003e1\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-2\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-2\"\u003e2\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-3\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-3\"\u003e3\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-4\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-4\"\u003e4\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-5\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-5\"\u003e5\u003c/a\u003e\n\u003c/span\u003e\u003cspan class=\"lnt\" id=\"hl-0-6\"\u003e\u003ca class=\"lnlinks\" href=\"#hl-0-6\"\u003e6\u003c/a\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003efib\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003en\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003en\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003en\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003efib\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003en\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"n\"\u003efib\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003en\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efib\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e","title":"公式和代码测试"},{"content":"👋 Hello World 这里写您的自我介绍\u0026hellip;\n","permalink":"http://localhost:1313/about/","summary":"\u003ch2 id=\"-hello-world\"\u003e👋 Hello World\u003c/h2\u003e\n\u003cp\u003e这里写您的自我介绍\u0026hellip;\u003c/p\u003e","title":"关于我"},{"content":"这是我的笔记正文。\n","permalink":"http://localhost:1313/posts/2026/01/%E5%9B%BE%E7%89%87%E6%B5%8B%E8%AF%95/","summary":"\u003cp\u003e这是我的笔记正文。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"笔记截图\" loading=\"lazy\" src=\"/posts/2026/01/%E5%9B%BE%E7%89%87%E6%B5%8B%E8%AF%95/2026-01-01-00-00-52.jpg\"\u003e\u003c/p\u003e","title":"图片测试"}]